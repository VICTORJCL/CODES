import streamlit as st
import os
from langchain_groq import ChatGroq
from langchain.prompts import ChatPromptTemplate
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.utilities import GoogleSearchAPIWrapper

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Asimo Web Explorer",
    page_icon="ü§ñ",
    layout="wide"
)

# Estilo CSS personalizado
st.markdown("""
    <style>
    .main {
        padding: 2rem;
    }
    .stTextInput {
        font-size: 1.2rem;
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        font-size: 1.1rem;
        line-height: 1.5;
    }
    .sources {
        font-size: 0.9rem;
        color: #666;
        padding: 1rem;
        background-color: #f0f2f6;
        border-radius: 0.5rem;
        margin-top: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)

# Configura√ß√µes das APIs
if 'initialized' not in st.session_state:
    os.environ["USER_AGENT"] = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    os.environ["GOOGLE_CSE_ID"] = "seu_search_engine_id"  # Substitua pelo seu ID
    os.environ["GOOGLE_API_KEY"] = "sua_api_key"  # Substitua pela sua API key
    os.environ['GROQ_API_KEY'] = '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'
    st.session_state.chat = ChatGroq(model='llama-3.1-70b-versatile')
    st.session_state.initialized = True

def pesquisar_e_coletar(query, num_results=3):
    search = GoogleSearchAPIWrapper()
    informacoes = []
    fontes = []
    
    try:
        results = search.results(query, num_results)
        
        for result in results:
            try:
                url = result["link"]
                loader = WebBaseLoader(url)
                docs = loader.load()
                informacoes.append(docs[0].page_content)
                fontes.append(f"{result['title']} - {url}")
            except Exception as e:
                continue
                
    except Exception as e:
        st.error(f"Erro na pesquisa: {str(e)}")
        
    return informacoes, fontes

# T√≠tulo principal
st.title("ü§ñ Asimo Web Explorer")
st.markdown("### Seu assistente para explorar a web")

# √Årea de entrada
query = st.text_input("O que voc√™ gostaria de saber?", key="user_input", 
                     placeholder="Digite sua pergunta aqui...")

# Bot√£o de pesquisa
if st.button("Pesquisar", type="primary"):
    with st.spinner("Pesquisando na web..."):
        informacoes, fontes = pesquisar_e_coletar(query)
        
        if not informacoes:
            st.error("Desculpe, n√£o consegui encontrar informa√ß√µes sobre isso.")
        else:
            # Preparar e enviar query para o chat
            template = ChatPromptTemplate.from_messages([
                ('system', '''Voc√™ √© um assistente amig√°vel chamado Asimo que analisa informa√ß√µes da web.
                Analise as seguintes informa√ß√µes para responder: {documentos_informados}
                
                Importante: Forne√ßa respostas bem estruturadas e detalhadas.'''),
                ('user', '{input}')
            ])
            
            chain = template | st.session_state.chat
            
            documento_completo = "\n\n".join(informacoes)
            
            # Processar resposta
            with st.spinner("Analisando informa√ß√µes..."):
                resposta = chain.invoke({
                    'documentos_informados': documento_completo,
                    'input': query
                })
            
            # Exibir resposta
            st.markdown("### Resposta:")
            st.markdown(f'<div class="chat-message">{resposta.content}</div>', 
                       unsafe_allow_html=True)
            
            # Exibir fontes
            st.markdown("### Fontes consultadas:")
            for fonte in fontes:
                st.markdown(f'<div class="sources">{fonte}</div>', 
                          unsafe_allow_html=True)

# Rodap√©
st.markdown("---")
st.markdown("Desenvolvido com ‚ù§Ô∏è usando Streamlit e LangChain")